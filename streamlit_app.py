"""
å­¦æ ¡ãƒªã‚¹ã‚¯äºˆå ±AI - Streamlit App
Gemini AI + Google Custom Search ã§ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¤œç´¢ãƒ»åˆ†æ
å­ã©ã‚‚äº‹ä»¶DBé€£æº + Supabaseã‚­ãƒ£ãƒƒã‚·ãƒ¥ + ãƒ¬ãƒ¼ãƒˆåˆ¶é™
"""

import streamlit as st
import google.generativeai as genai
import requests
import urllib.parse
import hashlib
from datetime import datetime, timedelta

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="å­¦æ ¡ãƒªã‚¹ã‚¯äºˆå ±AI",
    page_icon="ğŸ«",
    layout="centered"
)

# --- ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ™ãƒ¼ã‚¹ã®ãƒ¬ãƒ¼ãƒˆåˆ¶é™ ---
MAX_SEARCHES_PER_SESSION = 10

if "search_count" not in st.session_state:
    st.session_state.search_count = 0

def check_rate_limit() -> bool:
    return st.session_state.search_count < MAX_SEARCHES_PER_SESSION

def increment_search_count():
    st.session_state.search_count += 1

# --- Google Custom Search API ---
def google_search(query: str, num_results: int = 5) -> list:
    """Google Custom Search APIã§æ¤œç´¢"""
    try:
        api_key = st.secrets.get("GOOGLE_API_KEY", "")
        cx = st.secrets.get("GOOGLE_CX", "")
        
        if not api_key:
            st.error("âŒ GOOGLE_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return []
        if not cx:
            st.error("âŒ GOOGLE_CX ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return []
        
        url = "https://www.googleapis.com/customsearch/v1"
        params = {
            "key": api_key,
            "cx": cx,
            "q": query,
            "num": num_results,
            "lr": "lang_ja"
        }
        
        response = requests.get(url, params=params, timeout=10)
        
        if response.status_code != 200:
            error_data = response.json()
            error_msg = error_data.get("error", {}).get("message", "Unknown error")
            st.error(f"âŒ Google API ã‚¨ãƒ©ãƒ¼: {error_msg}")
            return []
        
        data = response.json()
        results = []
        for item in data.get("items", []):
            results.append({
                "title": item.get("title", ""),
                "link": item.get("link", ""),
                "snippet": item.get("snippet", "")
            })
        return results
    except Exception as e:
        st.error(f"âŒ æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {str(e)}")
    return []

# Supabaseèª­ã¿è¾¼ã¿
try:
    from supabase import create_client, Client
    supabase_available = True
except ImportError:
    supabase_available = False

# --- Supabaseè¨­å®š ---
supabase = None
cache_enabled = False

try:
    SUPABASE_URL = st.secrets["SUPABASE_URL"]
    SUPABASE_KEY = st.secrets["SUPABASE_KEY"]
    if supabase_available:
        supabase = create_client(SUPABASE_URL, SUPABASE_KEY)
        cache_enabled = True
except:
    pass

# ã‚­ãƒ£ãƒƒã‚·ãƒ¥é–¢æ•°
def generate_cache_key(school_name: str, prefecture: str) -> str:
    raw = f"{school_name}_{prefecture}".lower().strip()
    return hashlib.md5(raw.encode()).hexdigest()

def get_from_cache(search_key: str):
    if not cache_enabled or not supabase:
        return None
    try:
        response = supabase.table("school_risk_cache").select("*").eq("search_key", search_key).execute()
        if response.data and len(response.data) > 0:
            record = response.data[0]
            # ã‚¢ã‚¯ã‚»ã‚¹å›æ•°æ›´æ–°
            supabase.table("school_risk_cache").update({
                "access_count": record.get("access_count", 0) + 1,
            }).eq("id", record["id"]).execute()
            return record
    except:
        pass
    return None

def save_to_cache(school_name: str, prefecture: str, search_key: str, ai_result: str, search_results: str):
    if not cache_enabled or not supabase:
        return
    try:
        supabase.table("school_risk_cache").upsert({
            "school_name": school_name,
            "prefecture": prefecture,
            "search_key": search_key,
            "ai_result": ai_result,
            "search_results": search_results,
            "updated_at": datetime.now().isoformat()
        }).execute()
    except:
        pass

# å­ã©ã‚‚äº‹ä»¶ãƒ‡ãƒ¼ã‚¿
@st.cache_data(ttl=3600)
def load_child_cases():
    try:
        url = "https://tabekirimaru-glitch.github.io/meiyaku-knights/data/child-cases.json"
        response = requests.get(url, timeout=10)
        if response.status_code == 200:
            return response.json()
    except:
        pass
    return []

def find_related_cases(cases: list, search_term: str, prefecture: str, limit: int = 5):
    results = []
    search_keywords = []
    if prefecture != "æŒ‡å®šãªã—":
        search_keywords.append(prefecture.replace("çœŒ", "").replace("åºœ", "").replace("éƒ½", ""))
    
    for keyword in ["å¸‚", "åŒº", "ç”º", "æ‘"]:
        if keyword in search_term:
            idx = search_term.find(keyword)
            if idx > 0:
                search_keywords.append(search_term[:idx])
                break
    
    search_keywords.append(search_term)
    
    for case in cases:
        title = case.get("title", "")
        for keyword in search_keywords:
            if keyword and len(keyword) >= 2 and keyword in title:
                results.append(case)
                break
        if len(results) >= limit:
            break
    return results

# --- Gemini APIè¨­å®š ---
model = None
api_available = False

try:
    GEMINI_API_KEY = st.secrets["GEMINI_API_KEY"]
    genai.configure(api_key=GEMINI_API_KEY)
    
    available = []
    for m in genai.list_models():
        if 'generateContent' in m.supported_generation_methods:
            available.append(m.name)
    
    preferred = ['models/gemini-1.5-flash', 'models/gemini-1.5-pro', 'models/gemini-pro']
    selected = None
    for p in preferred:
        if p in available:
            selected = p
            break
    
    if not selected and available:
        selected = available[0]
    
    if selected:
        model = genai.GenerativeModel(selected)
        api_available = True
except:
    pass

# ã‚«ã‚¹ã‚¿ãƒ CSSï¼ˆãƒ€ãƒ¼ã‚¯ãƒ¢ãƒ¼ãƒ‰å¯¾å¿œï¼‰
st.markdown("""
<style>
    .main-header { font-size: 1.8rem; font-weight: 800; color: #1e3a5f; text-align: center; margin-bottom: 0.5rem; }
    .sub-header { font-size: 1rem; color: #64748b; text-align: center; margin-bottom: 2rem; }
    .search-result { background: #1e293b; padding: 0.75rem; border-radius: 8px; border: 1px solid #334155; margin-bottom: 0.5rem; }
    .search-result a { color: #60a5fa; text-decoration: none; font-weight: 600; }
    .search-result a:hover { text-decoration: underline; }
    .search-result p { color: #94a3b8; font-size: 0.85rem; margin-top: 0.25rem; }
    .cache-badge { background: #22c55e; color: white; padding: 0.25rem 0.5rem; border-radius: 4px; font-size: 0.75rem; }
    .warning-card { background: #7f1d1d; padding: 1rem; border-radius: 8px; border-left: 4px solid #f87171; margin: 0.5rem 0; color: #fecaca !important; }
    .warning-card strong { color: #fca5a5 !important; }
    .case-card { background: #1e293b; padding: 0.75rem; border-radius: 8px; border: 1px solid #334155; margin-bottom: 0.5rem; color: #e2e8f0 !important; }
    .case-card strong { color: #93c5fd !important; }
</style>
""", unsafe_allow_html=True)

# ãƒ˜ãƒƒãƒ€ãƒ¼
st.markdown('<div class="main-header">ğŸ« å­¦æ ¡ãƒªã‚¹ã‚¯äºˆå ±AI</div>', unsafe_allow_html=True)
st.markdown('<div class="sub-header">å­¦æ ¡åã‚’å…¥åŠ›ã—ã¦ã€AIã«ã‚ˆã‚‹å®‰å…¨æ€§åˆ†æã‚’ç¢ºèª</div>', unsafe_allow_html=True)

# æ¤œç´¢ãƒ•ã‚©ãƒ¼ãƒ 
col1, col2 = st.columns([3, 1])
with col1:
    school_name = st.text_input("å­¦æ ¡åã‚’å…¥åŠ›", placeholder="ä¾‹ï¼šã€‡ã€‡å¸‚ç«‹â–³â–³å°å­¦æ ¡", label_visibility="collapsed")
with col2:
    search_button = st.button("ğŸ” èª¿ã¹ã‚‹", type="primary", use_container_width=True)

prefecture = st.selectbox(
    "éƒ½é“åºœçœŒï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰",
    ["æŒ‡å®šãªã—"] + [
        "åŒ—æµ·é“", "é’æ£®çœŒ", "å²©æ‰‹çœŒ", "å®®åŸçœŒ", "ç§‹ç”°çœŒ", "å±±å½¢çœŒ", "ç¦å³¶çœŒ",
        "èŒ¨åŸçœŒ", "æ ƒæœ¨çœŒ", "ç¾¤é¦¬çœŒ", "åŸ¼ç‰çœŒ", "åƒè‘‰çœŒ", "æ±äº¬éƒ½", "ç¥å¥ˆå·çœŒ",
        "æ–°æ½ŸçœŒ", "å¯Œå±±çœŒ", "çŸ³å·çœŒ", "ç¦äº•çœŒ", "å±±æ¢¨çœŒ", "é•·é‡çœŒ", "å²é˜œçœŒ",
        "é™å²¡çœŒ", "æ„›çŸ¥çœŒ", "ä¸‰é‡çœŒ", "æ»‹è³€çœŒ", "äº¬éƒ½åºœ", "å¤§é˜ªåºœ", "å…µåº«çœŒ",
        "å¥ˆè‰¯çœŒ", "å’Œæ­Œå±±çœŒ", "é³¥å–çœŒ", "å³¶æ ¹çœŒ", "å²¡å±±çœŒ", "åºƒå³¶çœŒ", "å±±å£çœŒ",
        "å¾³å³¶çœŒ", "é¦™å·çœŒ", "æ„›åª›çœŒ", "é«˜çŸ¥çœŒ", "ç¦å²¡çœŒ", "ä½è³€çœŒ", "é•·å´çœŒ",
        "ç†Šæœ¬çœŒ", "å¤§åˆ†çœŒ", "å®®å´çœŒ", "é¹¿å…å³¶çœŒ", "æ²–ç¸„çœŒ"
    ],
    label_visibility="collapsed"
)

st.divider()

# AIåˆ†æé–¢æ•°
def analyze_with_search_results(school_name: str, prefecture: str, search_results: list) -> str:
    """Googleæ¤œç´¢çµæœã‚’å…ƒã«Geminiã§åˆ†æ"""
    location = f"{prefecture}ã®" if prefecture != "æŒ‡å®šãªã—" else ""
    
    # æ¤œç´¢çµæœã‚’ãƒ†ã‚­ã‚¹ãƒˆåŒ–
    search_text = ""
    for i, r in enumerate(search_results, 1):
        search_text += f"{i}. {r['title']}\n   URL: {r['link']}\n   æ¦‚è¦: {r['snippet']}\n\n"
    
    if not search_text:
        search_text = "æ¤œç´¢çµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
    
    prompt = f"""
ã‚ãªãŸã¯å­¦æ ¡ã®å®‰å…¨æ€§ã¨æ•™è‚²ç’°å¢ƒã‚’åˆ†æã™ã‚‹å°‚é–€å®¶AIã§ã™ã€‚
ä»¥ä¸‹ã®Googleæ¤œç´¢çµæœã‚’å…ƒã«ã€{location}{school_name}ã®è©³ç´°åˆ†æã‚’è¡Œã£ã¦ãã ã•ã„ã€‚

ã€Googleæ¤œç´¢çµæœã€‘
{search_text}

ã€åˆ†æé …ç›®ã€‘è¦ªã®è¦–ç‚¹ã§ä»¥ä¸‹ã‚’è©³ã—ãåˆ†æã—ã¦ãã ã•ã„ï¼š

1. **å®‰å…¨æ€§ãƒ»äº‹ä»¶æƒ…å ±**
   - éå»ã®äº‹ä»¶ãƒ»äº‹æ•…ãƒ»ã„ã˜ã‚å ±é“
   - å­¦æ ¡ã®å¯¾å¿œå§¿å‹¢ï¼ˆéš è”½å‚¾å‘ or é€æ˜æ€§ï¼‰

2. **åœ°åŸŸã®æ²»å®‰**
   - ä¸å¯©è€…æƒ…å ±ã®æœ‰ç„¡
   - é€šå­¦è·¯ã®å®‰å…¨æ€§
   - å‘¨è¾ºã®çŠ¯ç½ªç™ºç”ŸçŠ¶æ³

3. **æ•™è‚²ç’°å¢ƒ**
   - å­¦åŠ›æ°´æº–ãƒ»é€²å­¦å®Ÿç¸¾ï¼ˆæƒ…å ±ãŒã‚ã‚Œã°ï¼‰
   - éƒ¨æ´»å‹•ã®å……å®Ÿåº¦
   - ç‰¹åˆ¥æ”¯æ´ãƒ»ç™ºé”éšœå®³ã¸ã®å¯¾å¿œ

4. **ä¿è­·è€…ã®è©•åˆ¤**
   - å£ã‚³ãƒŸã‚µã‚¤ãƒˆã§ã®è©•ä¾¡
   - å…ˆç”Ÿã®è©•åˆ¤
   - PTAæ´»å‹•ã®è² æ‹…æ„Ÿ

5. **å­è‚²ã¦ç’°å¢ƒ**
   - å­¦ç«¥ä¿è‚²ã®çŠ¶æ³
   - å‘¨è¾ºã®ç¿’ã„äº‹ãƒ»å¡¾
   - åœ°åŸŸã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã®æ´»ç™ºã•

ã€å‡ºåŠ›å½¢å¼ã€‘
## ğŸ¯ ç·åˆè©•ä¾¡
[å®‰å¿ƒ/æ³¨æ„å¿…è¦/è¦è­¦æˆ’/æƒ…å ±ä¸è¶³] ã¨ç†ç”±ã‚’1-2æ–‡ã§

## ğŸš¨ å®‰å…¨æ€§ãƒ»äº‹ä»¶æƒ…å ±
ï¼ˆç™ºè¦‹ã•ã‚ŒãŸè¨˜äº‹ã¯URLã‚’å«ã‚ã¦è¨˜è¼‰ã€‚ãªã‘ã‚Œã°ã€Œé‡å¤§ãªäº‹ä»¶å ±é“ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€ï¼‰

## ğŸ˜ï¸ åœ°åŸŸã®æ²»å®‰
- ä¸å¯©è€…æƒ…å ±: 
- é€šå­¦è·¯: 
- å‘¨è¾ºæ²»å®‰: 

## ğŸ“š æ•™è‚²ç’°å¢ƒ
- å­¦åŠ›: 
- éƒ¨æ´»: 
- ç‰¹åˆ¥æ”¯æ´: 

## ğŸ‘¨â€ğŸ‘©â€ğŸ‘§ ä¿è­·è€…ã®è©•åˆ¤
ï¼ˆå£ã‚³ãƒŸæƒ…å ±ãŒã‚ã‚Œã°è¨˜è¼‰ï¼‰

## ğŸ  å­è‚²ã¦ç’°å¢ƒ
- å­¦ç«¥: 
- ç¿’ã„äº‹ãƒ»å¡¾: 

## ğŸ’¡ ã“ã®å­¦æ ¡ã‚’æ¤œè¨ä¸­ã®ä¿è­·è€…ã¸
ï¼ˆ2-3æ–‡ã®ã‚¢ãƒ‰ãƒã‚¤ã‚¹ï¼‰

## ğŸ”— å‚è€ƒã«ã—ãŸURL
ï¼ˆæ¤œç´¢ã§è¦‹ã¤ã‹ã£ãŸé‡è¦ãªURLã‚’ç®‡æ¡æ›¸ãï¼‰

---
â€»ã“ã®åˆ†æã¯{datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥')}æ™‚ç‚¹ã®Googleæ¤œç´¢çµæœã«åŸºã¥ãå‚è€ƒæƒ…å ±ã§ã™ã€‚
"""
    
    try:
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        return f"âš ï¸ åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"

def demo_analysis(school_name: str) -> str:
    return f"""
## ğŸ¯ ç·åˆãƒªã‚¹ã‚¯è©•ä¾¡
**æƒ…å ±ä¸è¶³** - Googleæ¤œç´¢APIãŒè¨­å®šã•ã‚Œã¦ã„ãªã„ãŸã‚ã€ãƒ‡ãƒ¢ãƒ¢ãƒ¼ãƒ‰ã§å‹•ä½œã—ã¦ã„ã¾ã™ã€‚

## ğŸ“° ç™ºè¦‹ã•ã‚ŒãŸè¨˜äº‹ãƒ»æƒ…å ±
Streamlit Secretsã«GOOGLE_API_KEYã¨GOOGLE_CXã‚’è¨­å®šã™ã‚‹ã¨ã€å®Ÿéš›ã®Googleæ¤œç´¢çµæœã‚’è¡¨ç¤ºã§ãã¾ã™ã€‚

## ğŸ“Š åˆ†æçµæœ
ï¼ˆãƒ‡ãƒ¢è¡¨ç¤ºï¼‰

## ğŸ’¡ ä¿è­·è€…ã¸ã®ã‚¢ãƒ‰ãƒã‚¤ã‚¹
å­¦æ ¡è¦‹å­¦ã‚„èª¬æ˜ä¼šã«å‚åŠ ã—ã¦ç¢ºèªã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚
"""

# æ¤œç´¢å®Ÿè¡Œ
if search_button and school_name:
    if not check_rate_limit():
        st.error(f"âš ï¸ æ¤œç´¢å›æ•°ã®ä¸Šé™ï¼ˆ{MAX_SEARCHES_PER_SESSION}å›ï¼‰ã«é”ã—ã¾ã—ãŸã€‚")
    else:
        search_key = generate_cache_key(school_name, prefecture)
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç¢ºèª
        cached = get_from_cache(search_key)
        
        if cached:
            st.success(f"ã€Œ{school_name}ã€ã®åˆ†æçµæœã‚’è¡¨ç¤º")
            st.markdown('<span class="cache-badge">âš¡ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰å–å¾—</span>', unsafe_allow_html=True)
            result = cached.get("ai_result", "")
            
            # ä¿å­˜ã•ã‚ŒãŸæ¤œç´¢çµæœã‚’è¡¨ç¤º
            if cached.get("search_results"):
                st.subheader("ğŸ” Googleæ¤œç´¢çµæœ")
                st.markdown(cached.get("search_results", ""))
        else:
            increment_search_count()
            remaining = MAX_SEARCHES_PER_SESSION - st.session_state.search_count
            
            with st.spinner("ğŸ” å¤šè§’çš„ã«æƒ…å ±åé›†ä¸­..."):
                # è¦ªç›®ç·šã®å¤šè§’çš„ãªã‚¯ã‚¨ãƒªã§æ¤œç´¢
                queries = [
                    f"{school_name} äº‹ä»¶ ã„ã˜ã‚",
                    f"{school_name} å£ã‚³ãƒŸ è©•åˆ¤",
                    f"{school_name} ä¸å¯©è€… æ²»å®‰"
                ]
                
                all_results = []
                seen_links = set()
                
                for q in queries:
                    results = google_search(q, num_results=3)
                    for r in results:
                        if r["link"] not in seen_links:
                            all_results.append(r)
                            seen_links.add(r["link"])
            
            # æ¤œç´¢çµæœã‚’è¡¨ç¤º
            if all_results:
                st.subheader("ğŸ” Googleæ¤œç´¢çµæœ")
                search_results_html = ""
                for r in all_results[:8]:  # æœ€å¤§8ä»¶è¡¨ç¤º
                    search_results_html += f"""
                    <div class="search-result">
                        <a href="{r['link']}" target="_blank">{r['title']}</a>
                        <p>{r['snippet'][:150]}...</p>
                    </div>
                    """
                st.markdown(search_results_html, unsafe_allow_html=True)
            else:
                st.info("Googleæ¤œç´¢çµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸï¼ˆAPIã‚­ãƒ¼æœªè¨­å®šã¾ãŸã¯ãƒ’ãƒƒãƒˆãªã—ï¼‰")
            
            with st.spinner("ğŸ¤– AIãŒåˆ†æä¸­..."):
                if api_available and all_results:
                    result = analyze_with_search_results(school_name, prefecture, all_results)
                    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜
                    save_to_cache(school_name, prefecture, search_key, result, search_results_html if all_results else "")
                else:
                    result = demo_analysis(school_name)
            
            st.success(f"ã€Œ{school_name}ã€ã®åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸ")
            if remaining > 0:
                st.caption(f"æ®‹ã‚Šæ¤œç´¢å›æ•°: {remaining}å›")
        
        # AIåˆ†æçµæœã‚’è¡¨ç¤º
        st.divider()
        st.subheader("ğŸ“Š AIåˆ†æçµæœ")
        st.markdown(result)
        
        # --- å­ã©ã‚‚äº‹ä»¶DBé€£æº ---
        st.divider()
        st.subheader("ğŸ“° å­ã©ã‚‚äº‹ä»¶DBã‹ã‚‰")
        
        child_cases = load_child_cases()
        related_cases = find_related_cases(child_cases, school_name, prefecture)
        
        if related_cases:
            st.info(f"é–¢é€£ã™ã‚‹äº‹ä»¶ãŒ **{len(related_cases)}ä»¶** è¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")
            for case in related_cases:
                st.markdown(f"""
                <div class="case-card">
                    <strong>ğŸ“… {case.get('date', 'æ—¥ä»˜ä¸æ˜')}</strong><br>
                    {case.get('title', 'ã‚¿ã‚¤ãƒˆãƒ«ãªã—')[:80]}...
                </div>
                """, unsafe_allow_html=True)
            
            st.markdown("""
            <a href="https://tabekirimaru-glitch.github.io/meiyaku-knights/child-cases.html" target="_blank" 
               style="display: inline-block; background: #7c3aed; color: white; padding: 0.5rem 1rem; border-radius: 8px; text-decoration: none;">
                ğŸ“Š å­ã©ã‚‚äº‹ä»¶DBã§è©³ã—ãè¦‹ã‚‹ â†’
            </a>
            """, unsafe_allow_html=True)
        else:
            st.info("ã“ã®åœ°åŸŸã®é–¢é€£äº‹ä»¶ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        
        # å…è²¬äº‹é …
        st.divider()
        st.markdown("""
        <div class="warning-card">
            <strong>âš ï¸ é‡è¦ãªæ³¨æ„äº‹é …</strong><br>
            ã“ã®çµæœã¯AIã«ã‚ˆã‚‹å…¬é–‹æƒ…å ±ã®åˆ†æã«åŸºã¥ãå‚è€ƒæƒ…å ±ã§ã™ã€‚
            å®Ÿéš›ã®å­¦æ ¡ã®å®‰å…¨æ€§ã‚’ä¿è¨¼ã™ã‚‹ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚
            æœ€çµ‚çš„ãªåˆ¤æ–­ã¯ã”è‡ªèº«ã§è¡Œã£ã¦ãã ã•ã„ã€‚
        </div>
        """, unsafe_allow_html=True)

elif search_button and not school_name:
    st.warning("å­¦æ ¡åã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")

# ãƒ•ãƒƒã‚¿ãƒ¼
st.divider()
st.markdown("""
<div style="text-align: center; color: #94a3b8; font-size: 0.85rem;">
    Â© 2025 ç‰‡ç¿¼ã®ç›Ÿç´„é¨å£«å›£ | 
    <a href="https://tabekirimaru-glitch.github.io/meiyaku-knights/" target="_blank">ã‚µã‚¤ãƒˆã«æˆ»ã‚‹</a>
</div>
""", unsafe_allow_html=True)
